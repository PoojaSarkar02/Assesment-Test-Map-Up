# -*- coding: utf-8 -*-
"""Assesment_Pooja.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KIvyuYEpLVTCGULTaDd8lOcpLDNP_qmF
"""



"""Question no. 5"""

import re

def find_all_dates(text):
    combined_pattern = r'\b(\d{2}-\d{2}-\d{4}|\d{2}/\d{2}/\d{4}|\d{4}\.\d{2}\.\d{2})\b'

    matches = re.findall(combined_pattern, text)

    return matches

text = "I Joined this office as on 23-08-2023, my friend on 09/23/2020, and another one on 2021.09.24."
print(find_all_dates(text))

"""Question No. 1"""

def reverse_in_groups(lst, n):
    result = []
    i = 0
    while i < len(lst):
        group = []
        for j in range(n):
            if i + j < len(lst):
                group.append(lst[i + j])
            else:
                break
        for k in range(len(group) - 1, -1, -1):
            result.append(group[k])
        i += n

    return result


print(reverse_in_groups(lst, n))

!pip install polyline

"""Question no.6"""

!pip install polyline # Install the polyline library

import pandas as pd
import polyline # Now the module can be imported
import numpy as np

def haversine_vectorized(lat1, lon1, lat2, lon2):
    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])

    dlat = lat2 - lat1
    dlon = lon2 - lon1
    a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2
    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))

    #radius_of_venus_as _example

    radius = 6051800
    return radius * c

def decode_polyline_and_calculate_distances(polyline_str):
    coordinates = polyline.decode(polyline_str)

    df = pd.DataFrame(coordinates, columns=['latitude', 'longitude'])

    distances = np.zeros(len(df))
    for i in range(1, len(df)):
        distances[i] = haversine_vectorized(df['latitude'][i-1], df['longitude'][i-1], df['latitude'][i], df['longitude'][i])

    df['distance'] = distances

    return df

polyline_str = "u{~hHoj@f#_@A|Fv}B}@hCjChF}X9}@cGyU]bA"
result_df = decode_polyline_and_calculate_distances(polyline_str)
print(result_df)

"""Question No.7"""

def rotate_and_transform_matrix(matrix):
    n = len(matrix)

    rotated_matrix = [[0] * n for _ in range(n)]
    for i in range(n):
        for j in range(n):
            rotated_matrix[j][n - 1 - i] = matrix[i][j]

    transformed_matrix = [[0] * n for _ in range(n)]

    for i in range(n):
        for j in range(n):
            row_sum = sum(rotated_matrix[i])
            col_sum = sum(rotated_matrix[k][j] for k in range(n))

            transformed_matrix[i][j] = row_sum + col_sum - rotated_matrix[i][j]

    return transformed_matrix

matrix = [[10, 20, 30],
          [40, 50, 60],
          [70, 80, 90]]

result = rotate_and_transform_matrix(matrix)
print(result)

"""Question No.2"""

def group_by_length(strings):
    result = {}

    for string in strings:
        length = len(string)
        if length not in result:
            result[length] = []
        result[length].append(string)

    sorted_result = dict(sorted(result.items()))

    return sorted_result

strings = ["Kavya", "Rohit", "guglu", "Shristi", "Pratima", "Munmun"]
print(group_by_length(strings))

"""Question no.8"""

import pandas as pd

def check_timestamp_completeness(df):
    df['startDay'] = pd.to_datetime(df['startDay'], errors='coerce').dt.strftime('%Y-%m-%d')
    df['endDay'] = pd.to_datetime(df['endDay'], errors='coerce').dt.strftime('%Y-%m-%d')

    df['start'] = pd.to_datetime(df['startDay'] + ' ' + df['startTime'], errors='coerce')
    df['end'] = pd.to_datetime(df['endDay'] + ' ' + df['endTime'], errors='coerce')

    df.set_index(['id', 'id_2'], inplace=True)

    grouped = df.groupby(level=[0, 1])

    def check_group(group):
        days = group['start'].dt.day_name().unique()
        complete_days = len(days) == 7
        time_ranges = [(group['start'].min(), group['start'].max())]

        full_day_coverage = all(
            ((time_range[1] - time_range[0]).total_seconds() >= 24 * 3600) for time_range in time_ranges
        )

        return not (complete_days and full_day_coverage)

    result = grouped.apply(check_group)

    return result

url = 'https://raw.githubusercontent.com/mapup/MapUp-DA-Assessment-2024/refs/heads/main/datasets/dataset-1.csv'
df = pd.read_csv(url)

incorrect_timestamps = check_timestamp_completeness(df)
print(incorrect_timestamps)

"""Question No. 3"""

def flatten_dict(d, parent_key='', sep='.'):
    flattened = {}

    def _flatten(obj, current_key):
        if isinstance(obj, dict):
            for k, v in obj.items():
                new_key = f"{current_key}{sep}{k}" if current_key else k
                _flatten(v, new_key)
        elif isinstance(obj, list):
            for i, v in enumerate(obj):
                new_key = f"{current_key}[{i}]"
                _flatten(v, new_key)
        else:
            flattened[current_key] = obj

    _flatten(d, parent_key)
    return flattened

nested_dict = {
    "Road": {
        "Name": "NH-10",
        "length": 850,
        "sections": [
            {
                "id": 1,
                "condition": {
                    "pavement": "Very Bad",
                    "traffic": "Heavy"
                }
            }
        ]
    }
}

flattened_dict = flatten_dict(nested_dict)
print(flattened_dict)

"""Question No. 4"""

from itertools import permutations

def unique_permutations(lst):
    all_permutations = permutations(lst)
    unique_perms = set(all_permutations)
    return [list(p) for p in unique_perms]

lst = [5, 5, 7]
result = unique_permutations(lst)
for perm in result:
    print(perm)